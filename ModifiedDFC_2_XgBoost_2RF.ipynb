{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary of File: Test the Optimized DFC with the XgBoost and RF as the base layers instead of only the Random Forest\n",
    "#All DFC layer combinations are tested with the AlexNet, ResNet, and MobileNet CNN combination for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "from pyexpat import model\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import locale\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense, Add, ZeroPadding2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy\n",
    "from sklearn import preprocessing\n",
    "import locale\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from deepforest import CascadeForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.layers import DepthwiseConv2D\n",
    "from tensorflow.keras.layers import ReLU, AvgPool2D\n",
    "\n",
    "#define the AlexNet CNN (acquired from AlexNet paper)\n",
    "def create_cnn_alexnet():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters = 96, input_shape = (224, 224, 3),  \n",
    "                kernel_size = (11, 11), strides = (4, 4),  \n",
    "                padding = 'valid')) \n",
    "    model.add(Activation('relu')) \n",
    "    # Max-Pooling  \n",
    "    model.add(MaxPooling2D(pool_size = (2, 2), \n",
    "                strides = (2, 2), padding = 'valid')) \n",
    "    # Batch Normalisation \n",
    "    model.add(BatchNormalization()) \n",
    "    \n",
    "    # 2nd Convolutional Layer \n",
    "    model.add(Conv2D(filters = 256, kernel_size = (11, 11),  \n",
    "                strides = (1, 1), padding = 'valid')) \n",
    "    model.add(Activation('relu')) \n",
    "    # Max-Pooling \n",
    "    model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2),  \n",
    "                padding = 'valid')) \n",
    "    # Batch Normalisation \n",
    "    model.add(BatchNormalization()) \n",
    "    \n",
    "    # 3rd Convolutional Layer \n",
    "    model.add(Conv2D(filters = 384, kernel_size = (3, 3),  \n",
    "                strides = (1, 1), padding = 'valid')) \n",
    "    model.add(Activation('relu')) \n",
    "    # Batch Normalisation \n",
    "    model.add(BatchNormalization()) \n",
    "    \n",
    "    # 4th Convolutional Layer \n",
    "    model.add(Conv2D(filters = 384, kernel_size = (3, 3),  \n",
    "                strides = (1, 1), padding = 'valid')) \n",
    "    model.add(Activation('relu')) \n",
    "    # Batch Normalisation \n",
    "    model.add(BatchNormalization()) \n",
    "    \n",
    "    # 5th Convolutional Layer \n",
    "    model.add(Conv2D(filters = 256, kernel_size = (3, 3),  \n",
    "                strides = (1, 1), padding = 'valid')) \n",
    "    model.add(Activation('relu')) \n",
    "    # Max-Pooling \n",
    "    model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2),  \n",
    "                padding = 'valid')) \n",
    "    # Batch Normalisation \n",
    "    model.add(BatchNormalization()) \n",
    "    \n",
    "    # Flattening \n",
    "    model.add(Flatten()) \n",
    "    \n",
    "    # 1st Dense Layer \n",
    "    model.add(Dense(4096, input_shape = (224*224*3, ))) \n",
    "    model.add(Activation('relu')) \n",
    "    # Add Dropout to prevent overfitting \n",
    "    model.add(Dropout(0.4)) \n",
    "    # Batch Normalisation \n",
    "    model.add(BatchNormalization()) \n",
    "    \n",
    "    # 2nd Dense Layer \n",
    "    model.add(Dense(4096)) \n",
    "    model.add(Activation('relu')) \n",
    "    # Add Dropout \n",
    "    model.add(Dropout(0.4)) \n",
    "    # Batch Normalisation \n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Dense(2048, activation = 'relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    return model\n",
    "\n",
    "#define the ResNet CNN and its associated blocks (acquired from ResNet Paper)\n",
    "def identity_block(X, f, filters, stage, block):\n",
    "   \n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    X_shortcut = X\n",
    "   \n",
    "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2a')(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b')(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c')(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
    "    X = Add()([X, X_shortcut])# SKIP Connection\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X\n",
    "\n",
    "def convolutional_block(X, f, filters, stage, block, s=2):\n",
    "   \n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    X_shortcut = X\n",
    "\n",
    "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '2a')(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b')(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c')(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
    "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1',)(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')         (X_shortcut)\n",
    "\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X\n",
    "#main ResNet Block\n",
    "def ResNet50(input_shape=(224, 224, 3)):\n",
    "\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', )(X)\n",
    "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "\n",
    "    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
    "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    X = X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    X = AveragePooling2D(pool_size=(2, 2), padding='same')(X)\n",
    "    headModel = Flatten()(X)\n",
    "    headModel=Dense(256, activation='relu', name='fc1')(headModel)\n",
    "    headModel=Dense(128, activation='relu', name='fc2')(headModel)\n",
    "    headModel = Dense( 1, name='fc3')(headModel)\n",
    "    model = Model(inputs=X_input, outputs=headModel, name='ResNet50')\n",
    "    return model\n",
    "\n",
    "# Define MobileNet block (acquired from MobileNet paper)\n",
    "def mobilnet_block (x, filters, strides):\n",
    "    \n",
    "    x = DepthwiseConv2D(kernel_size = 3, strides = strides, padding = 'same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    x = Conv2D(filters = filters, kernel_size = 1, strides = 1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def create_cnn_mobilenet():\n",
    "    input = Input(shape = (224,224,3))\n",
    "    x = Conv2D(filters = 32, kernel_size = 3, strides = 2, padding = 'same')(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # main part of the model\n",
    "    x = mobilnet_block(x, filters = 64, strides = 1)\n",
    "    x = mobilnet_block(x, filters = 128, strides = 2)\n",
    "    x = mobilnet_block(x, filters = 128, strides = 1)\n",
    "    x = mobilnet_block(x, filters = 256, strides = 2)\n",
    "    x = mobilnet_block(x, filters = 256, strides = 1)\n",
    "    x = mobilnet_block(x, filters = 512, strides = 2)\n",
    "    \n",
    "    for _ in range (5):\n",
    "        x = mobilnet_block(x, filters = 512, strides = 1)\n",
    "    x = mobilnet_block(x, filters = 1024, strides = 2)\n",
    "    x = mobilnet_block(x, filters = 1024, strides = 1)\n",
    "    x = AvgPool2D (pool_size = 7, strides = 1, data_format='channels_first')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(units = 1024, activation = 'relu')(x)\n",
    "    output = Dropout(0.4)(x)\n",
    "    output = Dense (1)(output)\n",
    "    model = Model(inputs=input, outputs=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "gasdata = pd.read_csv('path to CSV file of gas data (including labels for training)')\n",
    "data_dir = 'path to image files'\n",
    "#load the image files\n",
    "imagedata = sorted(os.listdir(data_dir))\n",
    "print(len(imagedata))\n",
    "X_data = []\n",
    "for image in imagedata:\n",
    "        img = mpimg.imread(\"path to image\")\n",
    "        img.resize(224,224,3)\n",
    "        img = img/255.0\n",
    "        X_data.append(img)\n",
    "images = np.array(X_data)\n",
    "#store loaded images\n",
    "\n",
    "trainImagesX = images\n",
    "trainAttrX = gasdata\n",
    "#load the training labels\n",
    "trainy = trainAttrX[\"Gas\"]\n",
    "#left with only gas data\n",
    "trainAttrX = trainAttrX.drop(columns=['Gas'])\n",
    "#normalize the gas data\n",
    "trainAttrX= (trainAttrX - np.min(trainAttrX)) / (np.max(trainAttrX) - np.min(trainAttrX))\n",
    "#load the pretrained AlexNet model\n",
    "alexnet = create_cnn_alexnet()\n",
    "model.load_weights(\"path to pretrained weights\")\n",
    "alexnetPredict = alexnet.predict(trainImagesX)\n",
    "print(alexnetPredict.shape)\n",
    "#get AlexNet predictions for gas leak images\n",
    "\n",
    "#load the pretrained ResNet model \n",
    "resnet = ResNet50()\n",
    "model.load_weights(\"path to pretrained weights\")\n",
    "resnetPredict = resnet.predict(trainImagesX)\n",
    "print(resnetPredict.shape)\n",
    "#get ResNet predictions for gas leak images\n",
    "\n",
    "#load pretrained MobileNet model\n",
    "mobilenet = create_cnn_mobilenet()\n",
    "model.load_weights(\"path to pretrained weights\")\n",
    "mobilenetPredict = mobilenet.predict(trainImagesX)\n",
    "print(mobilenetPredict.shape)\n",
    "#get MobileNet predictions\n",
    "\n",
    "#finalize preparing the train data\n",
    "alexnetPredict = np.array(alexnetPredict)\n",
    "resnetPredict = np.array(resnetPredict)\n",
    "mobilenetPredict = np.array(mobilenetPredict)\n",
    "trainAttrX = np.array(trainAttrX)\n",
    "trainAttrX.resize(5120,2)\n",
    "\n",
    "trainData = concatenate([alexnetPredict,resnetPredict,mobilenetPredict,trainAttrX])\n",
    "trainData = np.array(trainData)\n",
    "trainData.reshape(-1,1)\n",
    "\n",
    "print(trainData.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from deepforest import CascadeForestClassifier  \n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the base DFC model\n",
    "model = CascadeForestClassifier()\n",
    "\n",
    "#load the different base layers into the model per cascade layer\n",
    "n_estimators = 2  # the number of base estimators per cascade layer\n",
    "estimators = [XGBClassifier(n_estimators=100), XGBClassifier(n_estimators=100), RandomForestClassifier(random_state=3),RandomForestClassifier(random_state = 4)]\n",
    "model.set_estimator(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "model.fit(trainData, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Testing\n",
    "gasdata = pd.read_csv('path to simulated testing data (gas data and annotations)')\n",
    "#separate the gas data from the label\n",
    "result = gasdata['Gas']\n",
    "gasdata = gasdata.drop(columns=['Gas'])\n",
    "#normalize the simulated testing gas data \n",
    "gasdata= (gasdata - np.min(gasdata)) / (np.max(gasdata) - np.min(gasdata))\n",
    "#get image paths\n",
    "images =  sorted(os.listdir(\"path to thermal images for simulated testing data folder\"))\n",
    "#load and read the testing data\n",
    "X_dat = []\n",
    "for image in images:\n",
    "       img = mpimg.imread(\"path to image\")\n",
    "       #normalize the images \n",
    "       img.resize(224,224,3)\n",
    "       img = img/255.0\n",
    "       X_dat.append(img)\n",
    "test_images = np.array(X_dat)\n",
    "\n",
    "#use pretrained CNNs to get their predictions for the testing images\n",
    "alexnetPredictTest = np.array(alexnet.predict(test_images))\n",
    "resnetPredictTest = np.array(resnet.predict(test_images))\n",
    "mobilenetPredictTest = np.array(mobilenet.predict(test_images))\n",
    "print(alexnetPredictTest.shape)\n",
    "print(resnetPredictTest.shape)\n",
    "print(mobilenetPredictTest.shape)\n",
    "print(gasdata.shape)\n",
    "\n",
    "#finalize preparing the testing data\n",
    "testData = concatenate([alexnetPredictTest, resnetPredictTest, mobilenetPredictTest, gasdata])\n",
    "print(testData)\n",
    "print(testData.shape)\n",
    "\n",
    "#predict if there is gas leak or not on testing data\n",
    "performance = model.predict(testData)\n",
    "print(performance)\n",
    "actual = []\n",
    "for value in performance: \n",
    "    #print(value)\n",
    "    if(value>=0.5):\n",
    "            actual.append(1)\n",
    "    else:\n",
    "            actual.append(0)\n",
    "acutal = np.array(actual)\n",
    "\n",
    "#print the metrics for this model\n",
    "accuracy = accuracy_score(result, actual)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "precision = precision_score(result, actual)\n",
    "print('Precision: %f' % precision)\n",
    "recall = recall_score(result, actual)\n",
    "print('Recall: %f' % recall)\n",
    "f1 = f1_score(result, actual)\n",
    "print('F1 score: %f' % f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
